{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T21:57:40.307674Z","iopub.execute_input":"2025-11-10T21:57:40.307986Z","iopub.status.idle":"2025-11-10T21:57:40.313551Z","shell.execute_reply.started":"2025-11-10T21:57:40.307935Z","shell.execute_reply":"2025-11-10T21:57:40.312426Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n## ‚ÄºÔ∏è Please Read\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:24:51.931069Z","iopub.execute_input":"2025-11-12T22:24:51.932108Z","iopub.status.idle":"2025-11-12T22:24:52.101509Z","shell.execute_reply.started":"2025-11-12T22:24:51.932072Z","shell.execute_reply":"2025-11-12T22:24:52.100234Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:25:07.665672Z","iopub.execute_input":"2025-11-12T22:25:07.666033Z","iopub.status.idle":"2025-11-12T22:26:02.001598Z","shell.execute_reply.started":"2025-11-12T22:25:07.666001Z","shell.execute_reply":"2025-11-12T22:26:02.000502Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:26:06.878713Z","iopub.execute_input":"2025-11-12T22:26:06.880313Z","iopub.status.idle":"2025-11-12T22:26:06.886602Z","shell.execute_reply.started":"2025-11-12T22:26:06.880267Z","shell.execute_reply":"2025-11-12T22:26:06.885550Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.4: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config=types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504], # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:26:26.079038Z","iopub.execute_input":"2025-11-12T22:26:26.079375Z","iopub.status.idle":"2025-11-12T22:26:26.084726Z","shell.execute_reply.started":"2025-11-12T22:26:26.079349Z","shell.execute_reply":"2025-11-12T22:26:26.083686Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"---\n## ü§î Section 2: Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:27:50.493880Z","iopub.execute_input":"2025-11-12T22:27:50.494335Z","iopub.status.idle":"2025-11-12T22:27:50.503377Z","shell.execute_reply.started":"2025-11-12T22:27:50.494304Z","shell.execute_reply":"2025-11-12T22:27:50.501655Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:27:54.409677Z","iopub.execute_input":"2025-11-12T22:27:54.410637Z","iopub.status.idle":"2025-11-12T22:27:54.416982Z","shell.execute_reply.started":"2025-11-12T22:27:54.410599Z","shell.execute_reply":"2025-11-12T22:27:54.415757Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:28:16.982755Z","iopub.execute_input":"2025-11-12T22:28:16.983116Z","iopub.status.idle":"2025-11-12T22:28:16.991141Z","shell.execute_reply.started":"2025-11-12T22:28:16.983088Z","shell.execute_reply":"2025-11-12T22:28:16.990090Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"What are the latest advancements in quantum computing and what do they mean for AI?\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:28:37.778398Z","iopub.execute_input":"2025-11-12T22:28:37.779329Z","iopub.status.idle":"2025-11-12T22:28:45.687434Z","shell.execute_reply.started":"2025-11-12T22:28:37.779298Z","shell.execute_reply":"2025-11-12T22:28:45.686347Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > Here's a summary of the latest advancements in quantum computing and their implications for AI:\n\n*   **Quantum AI Emergence:** Advancements in quantum computing are creating \"Quantum AI,\" leveraging quantum mechanics for vastly superior speeds and computational power over classical AI.\n*   **Enhanced Capabilities:** Quantum AI offers exponential speedups for complex tasks like data analysis and optimization, potentially overcoming current AI limitations and improving machine learning through Quantum Machine Learning (QML).\n*   **Industry Transformation:** This fusion is expected to revolutionize sectors like healthcare (drug discovery), finance (risk assessment), and logistics through faster, more efficient problem-solving.\n*   **Sustainability Potential:** Quantum AI may lead to more sustainable AI by requiring fewer parameters for training, thus reducing computational costs and energy consumption.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n## üö• Section 3: Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:31:10.149306Z","iopub.execute_input":"2025-11-12T22:31:10.149704Z","iopub.status.idle":"2025-11-12T22:31:10.156346Z","shell.execute_reply.started":"2025-11-12T22:31:10.149678Z","shell.execute_reply":"2025-11-12T22:31:10.155155Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\",  # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:31:17.028875Z","iopub.execute_input":"2025-11-12T22:31:17.029616Z","iopub.status.idle":"2025-11-12T22:31:17.035491Z","shell.execute_reply.started":"2025-11-12T22:31:17.029584Z","shell.execute_reply":"2025-11-12T22:31:17.034470Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\",  # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:31:21.143665Z","iopub.execute_input":"2025-11-12T22:31:21.144065Z","iopub.status.idle":"2025-11-12T22:31:21.150026Z","shell.execute_reply.started":"2025-11-12T22:31:21.144034Z","shell.execute_reply":"2025-11-12T22:31:21.148968Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:31:25.511990Z","iopub.execute_input":"2025-11-12T22:31:25.512761Z","iopub.status.idle":"2025-11-12T22:31:25.518511Z","shell.execute_reply.started":"2025-11-12T22:31:25.512733Z","shell.execute_reply":"2025-11-12T22:31:25.517369Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a blog post about the benefits of multi-agent systems for software developers\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:31:29.666859Z","iopub.execute_input":"2025-11-12T22:31:29.667262Z","iopub.status.idle":"2025-11-12T22:31:36.211933Z","shell.execute_reply.started":"2025-11-12T22:31:29.667235Z","shell.execute_reply":"2025-11-12T22:31:36.210967Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here is a blog outline about the benefits of multi-agent systems for software developers:\n\n## **Headline:** Unleash the Power of Collaboration: How Multi-Agent Systems Are Revolutionizing Software Development\n\n**Introduction Hook:** Ever feel like you're juggling too many balls in the air as a software developer? Imagine a world where intelligent, autonomous \"teammates\" could tackle complex tasks, optimize workflows, and even predict potential issues before they arise. Welcome to the exciting realm of Multi-Agent Systems (MAS), a paradigm shift that's poised to transform how we build software.\n\n---\n\n### **Section 1: Enhanced Problem Solving and Complexity Management**\n\n*   **Decomposition for Clarity:** MAS allows developers to break down large, intricate problems into smaller, manageable sub-problems, each handled by a specialized agent. This makes the overall system easier to understand, design, and debug.\n*   **Distributed Intelligence:** Instead of a single monolithic system, MAS distributes computational power and decision-making across multiple agents. This can lead to more robust and resilient solutions, especially for problems with inherent parallelism.\n*   **Handling Dynamic Environments:** Agents can adapt and react to changing conditions in real-time, making MAS ideal for applications operating in unpredictable or evolving environments.\n\n---\n\n### **Section 2: Increased Efficiency and Automation**\n\n*   **Task Specialization and Optimization:** Individual agents can be designed and optimized for specific tasks, leading to higher performance and efficiency in their respective domains. Think of specialized agents for testing, deployment, or even code refactoring.\n*   **Autonomous Operation and Reduced Oversight:** Once configured, agents can operate autonomously, performing tasks without constant human intervention. This frees up developers to focus on higher-level design and innovation.\n*   **Scalability on Demand:** MAS architectures can be inherently scalable. As the system's needs grow, new agents can be introduced or existing ones scaled up, allowing for flexible and efficient resource utilization.\n\n---\n\n### **Section 3: Fostering Innovation and New Possibilities**\n\n*   **Emergent Behavior and Novel Solutions:** The interaction between multiple agents can lead to emergent behaviors that were not explicitly programmed, potentially uncovering innovative and unexpected solutions to complex challenges.\n*   **Simulations and \"What-If\" Scenarios:** MAS are powerful tools for creating realistic simulations, allowing developers to test different strategies, predict outcomes, and explore various design choices without impacting live systems.\n*   **Collaborative Development Environments:** Imagine agents that can actively participate in the development process, offering suggestions, identifying conflicts, and even generating boilerplate code, creating a more synergistic development experience.\n\n---\n\n**Concluding Thought:** Multi-Agent Systems are not just a theoretical concept; they represent a practical and powerful approach to building smarter, more efficient, and more resilient software. As developers, embracing this collaborative paradigm opens doors to tackling ever-increasing complexity and unlocking new frontiers in software innovation. It's time to think beyond the single developer and explore the incredible potential of intelligent, distributed collaboration.\nWriterAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Are Revolutionizing Software Development\n\nAs a software developer, do you ever feel overwhelmed by the sheer volume of tasks? Imagine offloading some of that burden to intelligent, autonomous \"teammates.\" This isn't science fiction; it's the reality of Multi-Agent Systems (MAS), a transformative approach to software development.\n\nMAS empowers us to tackle complexity head-on. By breaking down massive problems into smaller, specialized sub-problems, each handled by a dedicated agent, we gain unparalleled clarity. This distributed intelligence makes systems more robust and adaptable, especially in dynamic environments where real-time reactions are crucial.\n\nThe efficiency gains are profound. Agents can be hyper-optimized for specific functions ‚Äì think automated testing, deployment, or even intelligent code refactoring. This autonomy frees up valuable developer time, allowing us to focus on higher-level design and innovation rather than getting bogged down in routine tasks. Plus, MAS architectures are inherently scalable; simply add more agents as your project grows, ensuring flexibility and efficient resource management.\n\nBeyond efficiency, MAS unlocks new avenues for innovation. The interplay between agents can spark emergent behaviors, leading to creative and unexpected solutions. We can leverage MAS for sophisticated simulations, testing hypotheses and predicting outcomes without risking live systems. Envision a future where agents actively assist in development, suggesting code improvements and identifying conflicts, fostering a truly collaborative environment.\n\nEmbracing Multi-Agent Systems is about more than just building better software; it's about fundamentally rethinking our development process. It‚Äôs time to step into a future of intelligent, distributed collaboration and unlock unprecedented levels of software innovation.\nEditorAgent > ## Unleash the Power of Collaboration: How Multi-Agent Systems Are Revolutionizing Software Development\n\nAs a software developer, do you ever feel overwhelmed by the sheer volume of tasks? Imagine offloading some of that burden to intelligent, autonomous \"teammates.\" This isn't science fiction; it's the reality of Multi-Agent Systems (MAS), a transformative approach to software development.\n\nMAS empowers us to tackle complexity head-on. By breaking down massive problems into smaller, specialized sub-problems, each handled by a dedicated agent, we gain unparalleled clarity. This distributed intelligence makes systems more robust and adaptable, especially in dynamic environments where real-time reactions are crucial.\n\nThe efficiency gains are profound. Agents can be hyper-optimized for specific functions ‚Äì think automated testing, deployment, or even intelligent code refactoring. This autonomy frees up valuable developer time, allowing us to focus on higher-level design and innovation rather than getting bogged down in routine tasks. Furthermore, MAS architectures are inherently scalable; simply add more agents as your project grows, ensuring flexibility and efficient resource management.\n\nBeyond efficiency, MAS unlocks new avenues for innovation. The interplay between agents can spark emergent behaviors, leading to creative and unexpected solutions. We can leverage MAS for sophisticated simulations, testing hypotheses and predicting outcomes without risking live systems. Envision a future where agents actively assist in development, suggesting code improvements and identifying conflicts, fostering a truly collaborative environment.\n\nEmbracing Multi-Agent Systems is about more than just building better software; it's about fundamentally rethinking our development process. It‚Äôs time to step into a future of intelligent, distributed collaboration and unlock unprecedented levels of software innovation.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n## üõ£Ô∏è Section 4: Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\",  # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:32:46.878329Z","iopub.execute_input":"2025-11-12T22:32:46.878653Z","iopub.status.idle":"2025-11-12T22:32:46.885317Z","shell.execute_reply.started":"2025-11-12T22:32:46.878631Z","shell.execute_reply":"2025-11-12T22:32:46.883916Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:32:49.593610Z","iopub.execute_input":"2025-11-12T22:32:49.593913Z","iopub.status.idle":"2025-11-12T22:32:49.600896Z","shell.execute_reply.started":"2025-11-12T22:32:49.593892Z","shell.execute_reply":"2025-11-12T22:32:49.599880Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\",  # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:32:53.592200Z","iopub.execute_input":"2025-11-12T22:32:53.592502Z","iopub.status.idle":"2025-11-12T22:32:53.598504Z","shell.execute_reply.started":"2025-11-12T22:32:53.592482Z","shell.execute_reply":"2025-11-12T22:32:53.597378Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\",  # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:32:58.094297Z","iopub.execute_input":"2025-11-12T22:32:58.094612Z","iopub.status.idle":"2025-11-12T22:32:58.100374Z","shell.execute_reply.started":"2025-11-12T22:32:58.094587Z","shell.execute_reply":"2025-11-12T22:32:58.099421Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:33:08.245052Z","iopub.execute_input":"2025-11-12T22:33:08.245400Z","iopub.status.idle":"2025-11-12T22:33:08.252253Z","shell.execute_reply.started":"2025-11-12T22:33:08.245375Z","shell.execute_reply":"2025-11-12T22:33:08.250934Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Run the daily executive briefing on Tech, Health, and Finance\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:33:12.049794Z","iopub.execute_input":"2025-11-12T22:33:12.050158Z","iopub.status.idle":"2025-11-12T22:33:19.450026Z","shell.execute_reply.started":"2025-11-12T22:33:12.050131Z","shell.execute_reply":"2025-11-12T22:33:19.449082Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > ### Daily Executive Briefing: Tech, Health, and Finance\n\n**Health:** mRNA vaccine technology is rapidly expanding beyond COVID-19, with promising applications in cancer and other infectious diseases. Medical breakthroughs include the first living mitral valve replacement for children and advancements in brain-computer interfaces enabling speech for paralyzed individuals. Lab-grown blood is undergoing clinical trials, potentially revolutionizing treatments for blood disorders.\n\n**Tech:** Artificial intelligence (AI) continues its pervasive integration, powering advancements in automation, natural language processing, and personalized medicine. The rollout of 5G networks enhances connectivity, enabling innovations in autonomous vehicles and smart cities. Augmented and virtual reality (AR/VR) are transforming gaming, education, and remote collaboration.\n\n**Finance:** FinTech is experiencing rapid evolution with embedded finance, allowing non-financial brands to offer financial services. Decentralized Finance (DeFi) is maturing, with enhanced security and scalability. AI-driven personalization is becoming core to financial services, projected to reach over $614 billion by 2034. Biometric and invisible payment systems are emerging, enhancing convenience and security.\n\n**Estimated Timelines:**\n*   **Health:** mRNA vaccine applications are in ongoing trials and development, with broader adoption expected within 1-5 years. Brain-computer interfaces and lab-grown blood are in clinical trials, with potential for wider use in 5-10 years.\n*   **Tech:** AI integration is ongoing and accelerating. 5G is widely deployed, and AR/VR adoption is projected to grow significantly by 2025.\n*   **Finance:** Embedded finance is projected to reach $138 billion by 2026. AI in finance is expected to more than double by 2029. Biometric and invisible payments are emerging, with broader adoption anticipated in the next 3-7 years.\nTechResearcher > **AI/ML Trends Report: November 12, 2025**\n\n**Key Developments:**\n\n1.  **Generative AI Expansion:** Generative AI is moving beyond text to create complex multimedia content like graphics, video, and music, with significant market growth projected. Major players like Google (Imagen, Muse) and OpenAI are at the forefront.\n2.  **Rise of AI Agents:** AI-powered agents capable of independent task execution and collaboration are gaining traction, promising to revolutionize work processes and enhance autonomy. Companies like Microsoft (Copilot) are integrating these agents into their platforms.\n3.  **Edge AI and Optimized Computing:** Deploying ML models on edge devices is increasing due to the need for reduced latency and enhanced data privacy. This trend is supported by advancements in GPUs for faster model training.\n\n**Main Companies Involved:**\n\n*   **Generative AI:** Google, OpenAI, Microsoft, Stability AI, Synthesia.\n*   **AI Agents:** Microsoft, Google, IBM.\n*   **Edge AI/Optimized Computing:** NVIDIA (GPUs), Databricks (Data Platforms), IBM.\n\n**Potential Impact:**\n\nThese trends indicate a future where AI is more integrated into daily life and work, driving efficiency, innovation, and new economic opportunities. However, ethical considerations, data privacy, and workforce adaptation remain crucial challenges. The AI market is projected for substantial growth, contributing significantly to global GDP.\nFinanceResearcher > **Tech Trends**\n\n*   **Agentic AI and Context Engineering:** AI is moving beyond chatbots to autonomous agents that can perform complex tasks. This requires sophisticated \"context engineering\" to provide structured information for reliable AI performance. Market implication: Increased automation, efficiency, and demand for new AI development skills. Future outlook: Widespread adoption across industries, with a focus on responsible AI development and mitigating risks of autonomous systems.\n*   **AI Infrastructure and GPU Orchestration:** The demand for AI workloads is driving significant investment in infrastructure, particularly GPUs. Efficient orchestration is crucial due to high costs and processing needs. Market implication: Growth in cloud computing, specialized hardware, and hybrid cloud solutions. Future outlook: Continued innovation in AI hardware and optimization techniques to manage complex AI workloads.\n*   **Cybersecurity Innovations:** With evolving threats like ransomware and advanced persistent threats, AI-powered security solutions are becoming paramount. This includes enhanced threat detection and prevention. Market implication: Increased demand for cybersecurity professionals and solutions, focus on data security and privacy. Future outlook: AI will play an increasingly integral role in both offensive and defensive cybersecurity measures.\n\n**Health Trends**\n\n*   **AI for Diagnosis and Drug Discovery:** AI is revolutionizing healthcare by enabling earlier disease detection and accelerating drug development through advanced analytics and generative AI. Market implication: Faster development of treatments, more personalized medicine, and improved diagnostic accuracy. Future outlook: AI will become a standard tool for healthcare professionals, leading to better patient outcomes and more efficient healthcare systems.\n*   **Personalized and Precision Medicine:** Advances in genomics, gene editing (like CRISPR), and data analysis are enabling highly tailored treatments based on individual genetics, lifestyle, and environment. Market implication: Shift towards proactive and individualized healthcare, growth in related biotech industries. Future outlook: Increased focus on preventative care and genetic therapies for a range of conditions.\n*   **Mental Health Technology and Neurodiversity Awareness:** Technology is enhancing mental healthcare delivery through virtual sessions, AI-powered support, and increased awareness and acceptance of neurodiversity. Market implication: Greater accessibility to mental health services, reduced stigma, and tailored support for diverse cognitive needs. Future outlook: Integrated mental health support within broader wellness strategies and digital platforms.\n\n**Finance Trends**\n\n*   **Tokenization and Digital Assets:** The use of programmable ledgers and globally coordinated frameworks for tokenizing assets is set to enable faster, cheaper, and more secure financial transactions. Market implication: Increased efficiency in financial markets, potential for new investment products, and broader financial inclusion. Future outlook: Widespread adoption of tokenized assets, including Central Bank Digital Currencies (CBDCs) and stablecoins, transforming settlement processes.\n*   **AI in Finance:** AI is driving smarter, safer, and more inclusive financial services through trust, shared standards, and responsible innovation. Market implication: Enhanced risk management, fraud detection, personalized financial advice, and improved operational efficiency. Future outlook: AI will be deeply embedded in all aspects of financial services, from trading to customer service.\n*   **Global Market Corrections and Investor Caution:** Elevated asset valuations and persistent inflation are leading to a more cautious outlook, with potential for market corrections. Market implication: Increased focus on risk management, scenario planning, and adaptable investment strategies. Future outlook: A more dynamic and potentially volatile market environment requiring sophisticated analytical skills and a conservative approach to investment.**Executive Briefing: November 2025**\n\n**Technology:**\n*   **Agentic AI and Context Engineering:** AI is advancing towards autonomous agents capable of complex tasks, necessitating sophisticated \"context engineering\" for reliable performance. Market implication: Enhanced automation and efficiency; Future outlook: Widespread adoption with a focus on responsible AI.\n*   **AI Infrastructure and GPU Orchestration:** The surge in AI workloads is driving significant investment in GPU infrastructure and optimized orchestration. Market implication: Growth in cloud computing and specialized hardware; Future outlook: Continued innovation in AI hardware.\n*   **Cybersecurity Innovations:** AI-powered security solutions are crucial for defending against evolving threats. Market implication: High demand for cybersecurity solutions; Future outlook: AI integral to both cyber offense and defense.\n\n**Health:**\n*   **AI for Diagnosis and Drug Discovery:** AI is revolutionizing healthcare through early disease detection and accelerated drug development. Market implication: Faster treatment development and personalized medicine; Future outlook: AI as a standard healthcare tool.\n*   **Personalized and Precision Medicine:** Genomics and data analysis enable tailored treatments based on individual factors. Market implication: Shift to proactive, individualized care; Future outlook: Increased focus on preventative and genetic therapies.\n*   **Mental Health Technology & Neurodiversity:** Technology is improving mental healthcare access and acceptance of neurodiversity. Market implication: Greater accessibility to mental health services; Future outlook: Integrated mental health support.\n\n**Finance:**\n*   **Tokenization and Digital Assets:** Programmable ledgers and global frameworks are enabling faster, secure financial transactions. Market implication: Increased market efficiency and financial inclusion; Future outlook: Widespread adoption of tokenized assets and CBDCs.\n*   **AI in Finance:** AI is enhancing financial services through improved risk management, fraud detection, and personalization. Market implication: Optimized operations and customer experiences; Future outlook: Deep AI integration across financial services.\n*   **Market Corrections and Investor Caution:** Elevated valuations and inflation suggest potential market corrections. Market implication: Increased focus on risk management; Future outlook: Dynamic market environment requiring sophisticated strategies.\nAggregatorAgent > ## Executive Briefing: November 2025 - Key Trends in Tech, Health, and Finance\n\n**Artificial Intelligence (AI)** is the dominant theme across all sectors, driving transformative advancements. In technology, generative AI and sophisticated AI agents are poised for significant market growth, demanding robust infrastructure and enhanced cybersecurity. This AI integration directly impacts health, accelerating drug discovery, personalized medicine, and early disease detection, with AI becoming a standard healthcare tool. Similarly, finance is leveraging AI for smarter risk management, fraud detection, and personalized services, leading to deep integration across the sector.\n\nSurprising connections emerge: AI's role in personalized medicine mirrors its application in personalized financial advice, highlighting a broader trend of data-driven individualization. Furthermore, the ethical considerations and need for responsible AI development in technology echo the importance of trust and responsible innovation in AI-driven finance.\n\n**Key Takeaways:**\n*   **AI is pervasive:** Expect accelerated innovation and integration across technology, health, and finance.\n*   **Personalization is paramount:** Tailored solutions, from medicine to financial advice, are becoming the norm.\n*   **Data-driven advancements:** The convergence of AI, genomics, and sophisticated computing is fueling breakthroughs.\n*   **Market dynamics:** While technological progress promises growth, caution is advised in finance due to potential market corrections.\n*   **Emerging technologies:** mRNA, AR/VR, and tokenized assets represent significant future opportunities and disruptions.\n","output_type":"stream"}],"execution_count":21},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚û∞ Section 5: Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\",  # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:18.728078Z","iopub.execute_input":"2025-11-12T22:34:18.728469Z","iopub.status.idle":"2025-11-12T22:34:18.734573Z","shell.execute_reply.started":"2025-11-12T22:34:18.728445Z","shell.execute_reply":"2025-11-12T22:34:18.733335Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\",  # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:21.134188Z","iopub.execute_input":"2025-11-12T22:34:21.134516Z","iopub.status.idle":"2025-11-12T22:34:21.140647Z","shell.execute_reply.started":"2025-11-12T22:34:21.134490Z","shell.execute_reply":"2025-11-12T22:34:21.139540Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:25.175615Z","iopub.execute_input":"2025-11-12T22:34:25.175933Z","iopub.status.idle":"2025-11-12T22:34:25.181595Z","shell.execute_reply.started":"2025-11-12T22:34:25.175907Z","shell.execute_reply":"2025-11-12T22:34:25.180505Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=Gemini(\n        model=\"gemini-2.5-flash-lite\",\n        retry_options=retry_config\n    ),\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    output_key=\"current_story\",  # It overwrites the story with the new, refined version.\n    tools=[\n        FunctionTool(exit_loop)\n    ],  # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:27.931798Z","iopub.execute_input":"2025-11-12T22:34:27.932236Z","iopub.status.idle":"2025-11-12T22:34:27.938720Z","shell.execute_reply.started":"2025-11-12T22:34:27.932207Z","shell.execute_reply":"2025-11-12T22:34:27.937626Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":25},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2,  # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:30.693455Z","iopub.execute_input":"2025-11-12T22:34:30.693760Z","iopub.status.idle":"2025-11-12T22:34:30.700543Z","shell.execute_reply.started":"2025-11-12T22:34:30.693738Z","shell.execute_reply":"2025-11-12T22:34:30.699433Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\n    \"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-12T22:34:33.873144Z","iopub.execute_input":"2025-11-12T22:34:33.873477Z","iopub.status.idle":"2025-11-12T22:34:40.579201Z","shell.execute_reply.started":"2025-11-12T22:34:33.873449Z","shell.execute_reply":"2025-11-12T22:34:40.578146Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salt spray stung Elias‚Äôs weathered cheeks as he polished the Fresnel lens, the beam a familiar comfort against the encroaching dusk. For twenty years, this lonely tower had been his world. Tonight, however, felt different. A tremor, not of the sea, but of something *beneath* the waves, had rippled through the stone. He‚Äôd dismissed it, until his boot nudged something odd in the dusty corner of the keeper‚Äôs room.\n\nIt was a rolled parchment, tied with kelp. Unfurling it, Elias gasped. It was a map, but unlike any he‚Äôd ever seen. Intricate lines pulsed with a soft, bioluminescent blue, charting submerged islands and currents unknown. In the center, a single, radiant X marked a spot far out in the black ocean. A thrill, cold and sharp, shot through him. The sea was about to reveal its secrets.\nCriticAgent > This is a promising start to a story, with a strong sense of atmosphere and a compelling hook. Here are a few suggestions for improvement:\n\n1.  **Flesh out Elias's internal state:** While his reaction to the map is described as a \"thrill, cold and sharp,\" consider showing *why* this particular discovery would resonate with him. Has he always felt a pull towards the unknown? Is he bored with his routine? A brief glimpse into his inner thoughts before or after finding the map could deepen his character and make his motivation for pursuing the X more believable.\n\n2.  **Enhance the description of the map's mystery:** The bioluminescent lines and unknown currents are good starting points. To heighten the intrigue, you could add a detail that hints at the map's origin or purpose. For example, are there symbols on the map that Elias vaguely recognizes from old sea legends, or perhaps a cryptic inscription he can't decipher? This would further solidify its otherworldly nature.\n\n3.  **Consider a subtle foreshadowing of the \"something beneath the waves\":** The tremor is a great initial hint, but you could weave in another sensory detail earlier in the paragraph that subtly hints at this unusual event. Perhaps the sea itself behaved strangely before the tremor, or Elias heard an unusual sound. This would make the tremor feel less like a sudden, isolated event and more like a part of a larger, unfolding phenomenon.\nRefinerAgent > The salt spray stung Elias‚Äôs weathered cheeks as he polished the Fresnel lens, the beam a familiar comfort against the encroaching dusk. For twenty years, this lonely tower had been his world, a life of predictable tides and silent stars. He‚Äôd always found solace in the routine, yet lately, a quiet restlessness had settled in his bones, a yearning for something beyond the endless horizon. Tonight, however, felt different. The sea, usually a rhythmic lullaby, had been unnervingly still for hours, its surface like black glass. Then, a tremor, not of the sea, but of something *beneath* the waves, had rippled through the stone. He‚Äôd dismissed it as a ship‚Äôs passage, until his boot nudged something odd in the dusty corner of the keeper‚Äôs room.\n\nIt was a rolled parchment, tied with strands of kelp that still held a faint, briny scent. Unfurling it, Elias gasped, his breath catching in his throat. It was a map, but unlike any he‚Äôd ever seen. Intricate lines pulsed with a soft, bioluminescent blue, charting submerged islands and currents unknown. Strange, swirling symbols, reminiscent of ancient mariners' myths he'd only half-believed, adorned its edges. In the center, a single, radiant X marked a spot far out in the black ocean. A thrill, cold and sharp, shot through him, chasing away the boredom and igniting a spark of long-dormant adventure. The sea, his constant companion, was about to reveal its deepest secrets.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n## Section 6: Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}